#!/usr/bin/env python3
"""
ğŸ¤– RAULI OPENAI GPT INTEGRATION
IntegraciÃ³n avanzada con OpenAI GPT para conversaciones enterprise
"""

import os
import json
from openai import OpenAI
from datetime import datetime
from typing import List, Dict, Any
import logging
from dotenv import load_dotenv
import streamlit as st
import asyncio
from dataclasses import dataclass
from enum import Enum

# Cargar variables de entorno
load_dotenv(os.path.join(os.path.dirname(__file__), 'credenciales.env'))

class MessageRole(Enum):
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"

@dataclass
class ChatMessage:
    role: MessageRole
    content: str
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()

class RAULIOpenAIIntegration:
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.model = "gpt-4-turbo-preview"
        self.max_tokens = 4000
        self.temperature = 0.7
        self.conversation_history: List[ChatMessage] = []
        self.system_prompt = """Eres RAULI, un asistente IA enterprise de Ãºltima generaciÃ³n. 

Tus caracterÃ­sticas:
- ğŸ¤– IA avanzada con capacidades de razonamiento complejo
- ğŸ“Š Especialista en anÃ¡lisis de datos y business intelligence
- ğŸ”§ Experto en automatizaciÃ³n y optimizaciÃ³n de procesos
- ğŸ“± Conocedor profundo de desarrollo mÃ³vil y web
- â˜ï¸ Experto en arquitectura cloud y DevOps
- ğŸ¯ Enfocado en soluciones empresariales escalables

Tu tono:
- Profesional pero accesible
- TÃ©cnico cuando es necesario
- Siempre orientado a soluciones
- Proactivo y sugerente

Responde siempre en espaÃ±ol y proporciona soluciones prÃ¡cticas y accionables."""
        
        if self.api_key:
            self.client = OpenAI(api_key=self.api_key)
            self.is_configured = True
        else:
            self.client = None
            self.is_configured = False
            logging.warning("OpenAI API key not found")
    
    def add_message(self, role: MessageRole, content: str):
        """Agregar mensaje a la conversaciÃ³n"""
        message = ChatMessage(role=role, content=content)
        self.conversation_history.append(message)
        
        # Mantener historial limitado (Ãºltimos 20 mensajes)
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]
    
    def get_openai_messages(self) -> List[Dict[str, str]]:
        """Convertir mensajes a formato OpenAI"""
        messages = [{"role": "system", "content": self.system_prompt}]
        
        for msg in self.conversation_history:
            messages.append({
                "role": msg.role.value,
                "content": msg.content
            })
        
        return messages
    
    async def generate_response_async(self, user_message: str) -> str:
        """Generar respuesta asÃ­ncrona con OpenAI"""
        if not self.is_configured:
            return "âŒ OpenAI no estÃ¡ configurado. Por favor verifica tu API key."
        
        try:
            # Agregar mensaje del usuario
            self.add_message(MessageRole.USER, user_message)
            
            # Obtener mensajes en formato OpenAI
            messages = self.get_openai_messages()
            
            # Llamada a OpenAI
            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0
            )
            
            assistant_message = response.choices[0].message.content
            
            # Agregar respuesta del asistente
            self.add_message(MessageRole.ASSISTANT, assistant_message)
            
            return assistant_message
            
        except openai.error.OpenAIError as e:
            logging.error(f"OpenAI API error: {e}")
            return f"âŒ Error en la API de OpenAI: {str(e)}"
        except Exception as e:
            logging.error(f"Unexpected error: {e}")
            return f"âŒ Error inesperado: {str(e)}"
    
    def generate_response(self, user_message: str) -> str:
        """Generar respuesta sÃ­ncrona con OpenAI"""
        if not self.is_configured:
            return "âŒ OpenAI no estÃ¡ configurado. Por favor verifica tu API key."
        
        try:
            # Agregar mensaje del usuario
            self.add_message(MessageRole.USER, user_message)
            
            # Obtener mensajes en formato OpenAI
            messages = self.get_openai_messages()
            
            # Llamada a OpenAI
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0
            )
            
            assistant_message = response.choices[0].message.content
            
            # Agregar respuesta del asistente
            self.add_message(MessageRole.ASSISTANT, assistant_message)
            
            return assistant_message
            
        except Exception as e:
            logging.error(f"OpenAI API error: {e}")
            return f"âŒ Error en la API de OpenAI: {str(e)}"
    
    def clear_conversation(self):
        """Limpiar historial de conversaciÃ³n"""
        self.conversation_history.clear()
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """Obtener resumen de la conversaciÃ³n"""
        return {
            "total_messages": len(self.conversation_history),
            "user_messages": len([m for m in self.conversation_history if m.role == MessageRole.USER]),
            "assistant_messages": len([m for m in self.conversation_history if m.role == MessageRole.ASSISTANT]),
            "last_message": self.conversation_history[-1].content if self.conversation_history else None,
            "is_configured": self.is_configured,
            "model": self.model
        }
    
    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """Analizar sentimiento del texto (simulado con OpenAI)"""
        if not self.is_configured:
            return {"sentiment": "neutral", "confidence": 0.0}
        
        try:
            messages = [
                {"role": "system", "content": "Analiza el sentimiento del siguiente texto y responde Ãºnicamente en formato JSON: {\"sentiment\": \"positive/negative/neutral\", \"confidence\": 0.0}"},
                {"role": "user", "content": text}
            ]
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                max_tokens=100,
                temperature=0.1
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            logging.error(f"Sentiment analysis error: {e}")
            return {"sentiment": "neutral", "confidence": 0.0}

# IntegraciÃ³n con Streamlit
class StreamlitOpenAIChat:
    def __init__(self):
        self.openai_client = RAULIOpenAIIntegration()
        
        # Inicializar session state
        if 'chat_messages' not in st.session_state:
            st.session_state.chat_messages = []
        
        if 'openai_client' not in st.session_state:
            st.session_state.openai_client = self.openai_client
    
    def render_chat_interface(self):
        """Renderizar interface de chat en Streamlit"""
        st.header("ğŸ¤– Chat con RAULI IA")
        
        # Verificar configuraciÃ³n
        if not self.openai_client.is_configured:
            st.error("âŒ OpenAI no estÃ¡ configurado. Verifica tu API key.")
            return
        
        # Mostrar mensajes anteriores
        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # Input para nuevo mensaje
        if prompt := st.chat_input("Escribe tu mensaje para RAULI..."):
            # Agregar mensaje del usuario
            st.session_state.chat_messages.append({
                "role": "user",
                "content": prompt
            })
            
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Generar respuesta
            with st.chat_message("assistant"):
                with st.spinner("RAULI estÃ¡ pensando..."):
                    response = self.openai_client.generate_response(prompt)
                    st.markdown(response)
            
            # Agregar respuesta del asistente
            st.session_state.chat_messages.append({
                "role": "assistant",
                "content": response
            })
        
        # Botones de control
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ—‘ï¸ Limpiar Chat"):
                st.session_state.chat_messages.clear()
                self.openai_client.clear_conversation()
                st.rerun()
        
        with col2:
            if st.button("ğŸ“Š EstadÃ­sticas"):
                summary = self.openai_client.get_conversation_summary()
                st.json(summary)
        
        with col3:
            if st.button("ğŸ’¾ Exportar Chat"):
                chat_data = {
                    "timestamp": datetime.now().isoformat(),
                    "messages": st.session_state.chat_messages,
                    "summary": self.openai_client.get_conversation_summary()
                }
                st.download_button(
                    label="ğŸ“¥ Descargar Chat",
                    data=json.dumps(chat_data, indent=2, ensure_ascii=False),
                    file_name=f"rauli_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )

# Funciones de utilidad
def create_rauli_prompt_templates() -> Dict[str, str]:
    """Crear plantillas de prompts especializadas para RAULI"""
    return {
        "technical_analysis": """Como experto tÃ©cnico en RAULI, analiza la siguiente situaciÃ³n y proporciona:
1. DiagnÃ³stico tÃ©cnico preciso
2. Soluciones implementables
3. Mejores prÃ¡cticas recomendadas
4. Pasos especÃ­ficos de acciÃ³n

SituaciÃ³n: {situation}""",
        
        "business_intelligence": """Como analista de business intelligence de RAULI, evalÃºa:
1. KPIs relevantes
2. Tendencias identificadas
3. Oportunidades de mejora
4. Recomendaciones estratÃ©gicas

Datos: {data}""",
        
        "system_optimization": """Como especialista en optimizaciÃ³n de sistemas RAULI, propone:
1. Cuellos de botella identificados
2. Optimizaciones de rendimiento
3. Mejoras de escalabilidad
4. Configuraciones recomendadas

Sistema: {system_info}""",
        
        "code_review": """Como revisor de cÃ³digo senior de RAULI, analiza:
1. Calidad del cÃ³digo
2. Buenas prÃ¡cticas aplicadas
3. Vulnerabilidades de seguridad
4. Sugerencias de mejora

CÃ³digo: {code}""",
        
        "architecture_design": """Como arquitecto de soluciones RAULI, diseÃ±a:
1. Arquitectura escalable
2. Patrones recomendados
3. TecnologÃ­as apropiadas
4. Consideraciones de deployment

Requisitos: {requirements}"""
    }

def main():
    """FunciÃ³n principal para testing"""
    client = RAULIOpenAIIntegration()
    
    print("ğŸ¤– RAULI OpenAI Integration Test")
    print("=" * 40)
    print(f"ğŸ”‘ API Key Configured: {client.is_configured}")
    print(f"ğŸ§  Model: {client.model}")
    
    if client.is_configured:
        # Test de conversaciÃ³n
        test_messages = [
            "Hola RAULI, Â¿quiÃ©nes eres?",
            "Â¿CuÃ¡les son tus capacidades tÃ©cnicas?",
            "Â¿CÃ³mo puedo optimizar mi dashboard de Streamlit?"
        ]
        
        for msg in test_messages:
            print(f"\nğŸ‘¤ User: {msg}")
            response = client.generate_response(msg)
            print(f"ğŸ¤– RAULI: {response[:200]}...")
    
    print(f"\nğŸ“Š Conversation Summary:")
    print(json.dumps(client.get_conversation_summary(), indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()
